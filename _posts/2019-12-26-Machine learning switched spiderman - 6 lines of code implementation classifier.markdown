---
layout: post
title: 机器学习调包侠：6行代码实现分类器
date: 发布于2019-12-26 16:50:38 +0800
categories: 机器学习调包侠
tag: 4
---

* content
{:toc}

# 先做一个简短的说明

同样是一个学习笔记系列，只是记录一些个人学习过程中觉得值得记录一下的东西，不会做特别详细的说明。另外，看系列名字就知道，本系列只介绍现有的框架的用法，不涉及具体算法，并不适合想深入学习的同学，如果你只是想用别人写好的算法框架来实现一些有意思的想法，那么不妨来试试看。

<!-- more -->

# 环境搭建

本例主要使用scikit-learn，官网[戳这里](https://scikit-
learn.org)，中文文档[戳这里](https://sklearn.apachecn.org)，具体安装步骤这里就不废话了，文档上都有。

# 本篇对应教程

[油管原版](https://www.youtube.com/watch?v=cKxRvEZd3Mw)，[B站搬运](https://www.bilibili.com/video/av7200723)

# 分类器（Classifier）

现在，可以认为分类器就是一个函数，它接受一些数据作为输入，然后给这些数据打上标签作为输出，自动编写分类器的技术被成为监督式学习（supervised
learning）。

## 监督式学习

要使用监督式学习，我们需要遵循一些标准步骤：  
第一步是收集训练数据，这些是我们要解决问题的示例。对于每个示例来说，我们都有一个可以描述他们的测量方法（比如水果分类当中某个水果的颜色、外形等信息），在机器学习领域，这种测量方法被称为特征。描述每个种类的信息被成为标签，也就是分类的结果集。好的特征可以使得分类变得简单，能够用于训练的数据越多，能创建的分类器就更好。用程序来编写训练数据就是这样

    
    
    features = [[140克, 表面光滑], [130克, 表面光滑], [150克, 表面粗糙], [170克, 表面粗糙]]
    labels = [苹果, 苹果, 橘子, 橘子]
    

上面代码中，定义了两个变量——特征和标签，可以认为特征是分类器的输入，标签是分类器的输出。在本例中，我们用重量和表面光滑度来这两个特征来区分苹果和橘子，并且使用了4组数据，重量为140克表面光滑的是苹果，重量为130克表面光滑的也是苹果，重量150克表面粗糙的是橘子，重量为170表面粗糙的也是橘子。  
第二步是训练数据，我们即将用到的一种分类器被称作决策树（decision
tree），这里不做详细的介绍，只需要知道分类器就是一堆规则的组合即可，说白了就是用这个算法就能分类了  
第三步是使用分类器，就是输入一个新示例的特征，看分类器输出的标签是什么

# 代码

    
    
    # 引入决策树算法
    from sklearn import tree
    
    # 准备训练数据
    features = [[140, 1], [130, 1], [150, 0], [170, 0]]
    labels = [0, 0, 1, 1]
    
    # 创建一个分类器，它现在还是没有任何规则的空盒子
    clf = tree.DecisionTreeClassifier()
    
    # 用学习算法去训练分类器，可以认为学习算法就是创建规则的过程
    # 它通过在给定的训练数据中找到规律来生成规则
    # 在sklearn中，分类器对象中的训练算法被成为fit，可以认为fit就是在数据中找到规律
    clf = clf.fit(features, labels)
    
    # 输入一个新例子的特征数据，看分类器将它识别成了什么
    print(clf.predict([[150, 0]]))
    

